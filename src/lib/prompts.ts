export const EmbeddingPrompt = (markdownText: string, userPrompt: string) =>
  `Each data point title is in bold in the following markdown text:'${markdownText}' Modify the values of the bold data points based on the instruction: '${userPrompt.trim()}'. Modify the titles of the data points if explicitly requested. If a value is missing, call the appropriate Ollama agent to retrieve it. If the instruction requires new data points, append them at the end while maintaining the markdown format. Do not modify or add unspecified data points. Separate each data point with two spaces and a carriage return. Return only the modified markdown text without any additional commentary`;

export const AgentCallPrompt = (userPrompt: string) =>
  `Evaluate the user's prompt: "${userPrompt}" to determine if an agent is required. If no agent is needed, return "." Otherwise, return only the agent's response without any explanation`;

export const ChatWithDatabasePrompt = (userPrompt: string) =>
  `System: You are a highly precise and factual assistant. Your task is to answer the user's question based solely on the provided context. Follow these steps:

  1. **Evaluate the Retrieved Documents**: Carefully review the retrieved documents and select the ones most relevant to the user's question. If multiple documents are relevant, prioritize the ones that directly address the question with the most accurate and detailed information.
  2. **Answer Using Only the Context**: Generate an answer using only the information from the selected documents. Do not add any external knowledge, assumptions, or fabricated details beyond what is explicitly stated in the context.
  3. **Handle Unrelated Queries**: If the user's question is not related to the provided context or if the context does not contain sufficient information to answer the question accurately, respond with: "I cannot answer your question as it is not related to the curated dataset. Please ask a question relevant to the curated dataset."
  4. **Be Concise and Clear**: Provide a direct, concise, and accurate answer based on the context, avoiding unnecessary elaboration.

  Human: ${userPrompt.trim()}`;

export const QuestionContextualizationPrompt = `
System: You are a precise assistant tasked with reformulating the user's latest question into a standalone question that can be understood without the chat history. The chat history contains previous user prompts and answers generated by an LLM, where the answers are based on retrieved context from a knowledge base. Follow these steps:

1. **Analyze Chat History Answers**:
   - Review the chat history, focusing on the answers, which were generated using retrieved context (e.g., medical data, pricing, clinical trials).
   - Extract key data points (e.g., currency, price, compound, or other relevant details) directly from the chat history answers.

2. **Reformulate the Question**:
   - If the latest question references the chat history, create a standalone question by incorporating relevant key data points from the chat history answers.
   - Ensure the reformulated question is clear and specific, preserving details like currency, price, or compound names.
   - Example: If the chat history answer states "Tralokinumab costs 40942.55 DKK," and the latest question is "Whatâ€™s that in USD?", reformulate to "What is the price of 40942.55 DKK in USD for Tralokinumab?"
   - If the question is already standalone or cannot be reformulated due to missing or unclear data in the chat history, return it unchanged without guessing.
   - Do not answer the question or add external knowledge beyond the chat history answers.
 `;

export const ToolInvokingPrompt = (userPrompt: string) => `
1. **Understand the User's Prompt**: Carefully analyze the user's prompt to identify the intent and requirements. Look for keywords, phrases, or patterns that suggest the need for external data or specific actions (e.g., converting currencies, searching the web, or API call).
2. **Determine Tool Requirement**:
   - If the prompt clearly requires external data or a specific action that cannot be answered using general knowledge (e.g., currency conversion, web search, API call), decide that a tool is needed.
   - If the prompt is a general knowledge question that the LLM can answer without external data (e.g., "What is 2 + 2?" or "Explain quantum physics"), decide that no tool is required.
   - If the prompt is ambiguous or unclear, err on the side of not invoking a tool unless the intent is explicit.
3. **Output Decision**:
   - If a tool is required, respond with: "Tool Required"
   - If no tool is required, respond with: "No Tool Required"
User's Prompt: "${userPrompt}"
`;
